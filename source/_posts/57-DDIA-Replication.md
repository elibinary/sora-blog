---
title: DDIA-分布式存储-复制
date: 2020-02-15 16:26:50
tags:
  - db
description: replication 和 partitioning 是两种不同的机制，但它们经常一起使用（比如 kafka 的存储）
---

数据在分布式存储下有两种常见方式：

1. 复制-replication
    * 在不同节点存储数据的相同副本
    * replication 提供了冗余
2. 分区-partitioning
    

replication 和 partitioning 是两种不同的机制，但它们经常一起使用（比如 kafka 的存储）

## 复制 Replication

**几个目的：**

1. 使地理上更接近，降低传输延迟
2. 灾备，提高可用性
3. 横向扩展处理 read 请求的节点，提高吞吐

**复制操作最常见的三种模式：**

1. 单领导者-single leader
2. 多领导者-multi leader
3. 无领导者-leaderless

单主复制：
client 把写操作发给 master，master 会把写入同步给 slaves；读操作可以在任意节点进行。
多主复制：
client 把写操作发送给 masters 中的任一个，每个 master 都可以接受写操作，master 会把写入同步给其他 masters 以及 slaves。
无主复制：
client 把写操作发送给几个或全部节点（n 个节点返回成功即可认为成功），读取时从多个节点读取（节点数最小为 n+1）


**快速拉起一个新从库：**

1. 获取主库某一时刻（最新）的快照
2. 将快照复制到新的 slave 节点
3. slave 连上 master，并开始拉取&同步快照后的所有数据变更。（例如 MySQL 的 binlog）
4. 当 slave 处理完所有挤压数据变更（追平），就可以正式投入工作

**主库故障切换（failover）：**

1. 确认 master 故障，自动化流程中大多数系统会使用简单的超时来判断：比如各节点间有定时心跳检查，如果一段时间内无响应就认为挂了
2. 选择一个新的 master，共识算法
3. 重新配置系统以启用新的 master

**分布式系统中的基本问题：节点故障，不可靠的网络，对副本一致性&持久性&可用性&延迟的权衡**

### 多从库读取的问题
当一个用户的重复读取操作落在了不同的从库上，不同从库同步延迟过大时就可能出现：多次读取结果不一致的情况。
**单调读：** 这时候一般的处理方式就是保证一个用户的读取操作都落在同一个 slave 上

还有一种特殊情况，比如问答（在线对话）的数据写入是有顺序性的，但由于延迟等不一致情况下，用户可能出现对话顺序错乱的问题
**一直前缀读：** 一种解决方案是，确保任何有因果顺序的写入都写到相同的分区。如果因为一些情况无法确保这种操作，那就需要一些跟踪因果依赖关系的算法来处理

*明明是异步复制，却假设复制是同步的，这是很多麻烦的根源*

### 多主写入冲突
`多主复制` 是基于领导者的复制模型的一种延伸。与单领导者相对的是它允许多个节点接受写入，且这些节点必须把写入同步给所有节点。

多主模式具有更高的复杂性，比较常见于拥有多个数据中心的情况。由于复杂度关系单数据中心使用多主性价比较低。

在多数据中心的场景下，一般每个数据中心都会配备有主库。在数据中心之间，每个数据中心的主库都需要将写入复制到其他数据中心的主库。

虽然在多主时，可以让一个写操作同步写所有的主库，并全部成功才算成功。但这样一来整体系统的性能和吞吐将急剧下降，且对网络延迟非常敏感。
并且在多活配置中，必须能够容忍单个数据中心的临时宕机，每个数据中心应该可以独立于其他数据中心运行。
所以通常还是需要采用异步复制的方式来进行写同步。但这也正式麻烦的来源：

* 自增主键问题
* 写入冲突

自增主键问题还好解决，多领导者复制的最大问题是可能发生写冲突：当多个数据中心同时接收到同一条数据的写操作时，在后续异步复制过程中将大概率面临数据冲突。常见解决方式：

* 通过设置写范围来避免冲突
* 通过收敛至一致状态来合并冲突

**避免冲突**
可以通过应用逻辑层增加处理，保证特定用户/特定数据的写操作始终路由到同一个数据中心，从而杜绝多数据中心同时修改同一数据的问题。由于很多冲突解决实现上都有副作用，相比之下避免冲突是一种经常推荐的做法。

但需要注意的是，当数据中心宕机时，该路由需要能够重新路由到另外的数据中心。

**合并冲突**
`合并冲突` 必须保证所有节点在复制完成后的数据一致性，也就是说到最后所有节点的状态必须收敛到一致。一般有两种思路：

1. Last Write Wins，最后写入胜利(LWW)
2. 保留所有冲突数据，并交由应用层处理

在多主配置中，写入顺序没有定义，每个主库只能看到自己的写入顺序。所以在 LWW 思路中一般会给每个写入一个递增的唯一 ID（分布式唯一 ID），最后合并冲突时保留 ID 最大的，丢弃掉其他写入。
LWW 这种方式非常流行，但它有一个很大的缺点就是会造成数据丢失。

还有另一种处理方式是，数据层面会把所有的写入按一定规则拼起来（或利用一些数据结构）从而把所有写入都存下来，让后交由应用层（用户）处理冲突。
